# Fairness Contract
This repository contains the source code, benchmark models, and datasets for the paper - "FairSpec: Fairness Contracts for Machine Learning Pipelines"

## Abstract
Ensuring algorithmic fairness in machine learning (ML) systems remains a fundamental software engineering challenge. Existing bias detection and mitigation techniques are primarily post hoc interventions, lacking mechanisms for modular, design-time specification or actionable localization of fairness violations. We present FairSpec, the first framework to introduce fairness contracts, which is a modular, design-by-contract (DbC) specification mechanism that can be attached to individual components of the ML pipeline. Unlike prior approaches, FairSpec enables developers to proactively declare and enforce fairness properties, including both hyperproperties and probabilistic fairness requirements, at multiple stages of the pipeline, not just globally. FairSpec contract mechanism supports runtime assertion checking, allowing for immediate detection and precise localization of fairness bugs as soon as they arise. We construct a benchmark of 24 fairness contracts across diverse pipeline components and empirically demonstrate that, while existing bias mitigation methods are not directly comparable, FairSpec detects 40 out of 45 seeded fairness bugs (compared to 37/45 for the strongest baseline), and localizes bugs substantially faster than the state-of-the-art. By making modular fairness specification and enforcement a first-class SE construct, FairSpec establishes a new direction for fairness-aware software engineering in ML pipelines.
